{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "TRAIN_DIR = '/home/kriti/Documents/Untitled Folder/Untitled Folder/train'\n",
    "TEST_DIR = '/home/kriti/Documents/Untitled Folder/Untitled Folder/test1'\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'dogs-vs-cats-convnet'\n",
    "\n",
    "def create_label(image_name):\n",
    "    \"\"\" Create an one-hot encoded vector from image name \"\"\"\n",
    "    word_label = image_name.split('.')[-3]\n",
    "    if word_label == 'cat':\n",
    "        return np.array([1,0])\n",
    "    elif word_label == 'dog':\n",
    "        return np.array([0,1])\n",
    "\n",
    "\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
    "        training_data.append([np.array(img_data), create_label(img)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n",
    "\n",
    "\n",
    "def create_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append([np.array(img_data), img_num])\n",
    "\n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 11489  | total loss: \u001b[1m\u001b[32m0.10016\u001b[0m\u001b[0m | time: 35.888s\n",
      "| Adam | epoch: 030 | loss: 0.10016 - acc: 0.9542 -- iter: 24448/24500\n",
      "Training Step: 11490  | total loss: \u001b[1m\u001b[32m0.10006\u001b[0m\u001b[0m | time: 36.984s\n",
      "| Adam | epoch: 030 | loss: 0.10006 - acc: 0.9525 | val_loss: 0.96241 - val_acc: 0.7740 -- iter: 24500/24500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If dataset is not created:\n",
    "train_data = create_train_data()\n",
    "test_data = create_test_data()\n",
    "\n",
    "# If you have already created the dataset:\n",
    "# train_data = np.load('train_data.npy')\n",
    "# test_data = np.load('test_data.npy')\n",
    "\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y_train = [i[1] for i in train]\n",
    "\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y_test = [i[1] for i in test]\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log', tensorboard_verbose=0)\n",
    "\n",
    "model.fit({'input': X_train}, {'targets': y_train}, n_epoch=30,\n",
    "          validation_set=({'input': X_test}, {'targets': y_test}),\n",
    "          snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: {0.007809331}, dog: {0.99219066}\n"
     ]
    }
   ],
   "source": [
    "d = test_data[0]\n",
    "img_data, img_num = d\n",
    "\n",
    "data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "prediction = model.predict([data])[0]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img_data, cmap=\"gray\")\n",
    "print(\"cat: {%s}, dog: {%s}\"%(prediction[0], prediction[1]))\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, data in enumerate(test_data[:16]):\n",
    "\n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "\n",
    "    y = fig.add_subplot(4, 4, num + 1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    model_out = model.predict([data])[0]\n",
    "\n",
    "    if np.argmax(model_out) == 1:\n",
    "        str_label = 'Dog'\n",
    "    else:\n",
    "        str_label = 'Cat'\n",
    "\n",
    "    y.imshow(orig, cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
